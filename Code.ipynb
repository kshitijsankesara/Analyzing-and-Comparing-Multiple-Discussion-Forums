{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = PlaintextCorpusReader('.','.*\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiDis = mycorpus.raw('HW_WikipediaDiscussions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphafilter(w):\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bsoup = BeautifulSoup(wikiDis, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = Bsoup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiDistokens = nltk.word_tokenize(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiDiswords = [w.lower() for w in wikiDistokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphawikiDiswords = [w for w in wikiDiswords if not alphafilter(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwikiDiswords = [w for w in alphawikiDiswords if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "wikiDisdist = FreqDist(stopwikiDiswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiDisitems = wikiDisdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('article', 0.009396865054310331)\n",
      "('wp', 0.008808487171781502)\n",
      "(''s', 0.005351558484692799)\n",
      "('sources', 0.005260253390290695)\n",
      "('n't', 0.004583908449069086)\n",
      "('notability', 0.004267187766766732)\n",
      "('notable', 0.003701783424119723)\n",
      "('coverage', 0.003097697138252898)\n",
      "('new', 0.003069422012244504)\n",
      "('please', 0.0026990964035512382)\n",
      "('per', 0.0026451969445977375)\n",
      "('add', 0.002602293367980835)\n",
      "('one', 0.00256960025353363)\n",
      "('comments', 0.0025573280634258204)\n",
      "('thanks', 0.0025144244868089173)\n",
      "('notice', 0.0024675938093575156)\n",
      "('reliable', 0.002315418652020675)\n",
      "('wikipedia', 0.0022595556426499254)\n",
      "('articles', 0.002198096514590014)\n",
      "('would', 0.0021138602016900084)\n",
      "('gng', 0.002065753216467394)\n",
      "('fails', 0.0018772523764114368)\n",
      "('subject', 0.0017213464732818223)\n",
      "('also', 0.0016842353703958057)\n",
      "('page', 0.0016246416152322816)\n",
      "('find', 0.0015705458012370563)\n",
      "('see', 0.001466281274081105)\n",
      "('significant', 0.0014544017940567452)\n",
      "('list', 0.0014439949768453226)\n",
      "('like', 0.0013574024034446173)\n",
      "('independent', 0.0012908380442998573)\n",
      "('enough', 0.0012872054760279456)\n",
      "('even', 0.0012868127659444958)\n",
      "('could', 0.0012123942051307376)\n",
      "('source', 0.0011912860381453048)\n",
      "('seems', 0.0011431790529226908)\n",
      "('afd', 0.0010997845887014757)\n",
      "('meet', 0.0010951702452209392)\n",
      "('deletion', 0.0010870215109893536)\n",
      "('think', 0.0010746511433606814)\n",
      "('references', 0.0010596299826687223)\n",
      "('delete', 0.000986193197063589)\n",
      "('may', 0.0009464313011142854)\n",
      "('news', 0.0009311156078597389)\n",
      "('found', 0.0009270903295043773)\n",
      "(''m', 0.0008862484808255866)\n",
      "('non-notable', 0.0008740744682386393)\n",
      "('nothing', 0.0008400068684993596)\n",
      "('google', 0.0008345089273310608)\n",
      "('two', 0.000833527152122436)\n"
     ]
    }
   ],
   "source": [
    "for item in wikiDisitems:\n",
    "    print('(\\'' + str(item[0]) + '\\', ' + str(item[1]/len(wikiDiswords)) +')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiDisbigrams = list(nltk.bigrams(wikiDiswords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "Bmeasures = nltk.collocations.BigramAssocMeasures()\n",
    "Bfinder = BigramCollocationFinder.from_words(stopwikiDiswords)\n",
    "Bscored = Bfinder.score_ngrams(Bmeasures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('please', 'add'), 0.005497985571914642)\n",
      "(('add', 'new'), 0.005488940600997615)\n",
      "(('new', 'comments'), 0.005485774861176656)\n",
      "(('comments', 'notice'), 0.005484870364084953)\n",
      "(('notice', 'thanks'), 0.005483513618447399)\n",
      "(('wp', 'gng'), 0.0035022127390727143)\n",
      "(('fails', 'wp'), 0.0031786289045160863)\n",
      "(('reliable', 'sources'), 0.0028729088875205856)\n",
      "(('per', 'wp'), 0.0019100717334031001)\n",
      "(('significant', 'coverage'), 0.0016938969284861635)\n",
      "(('non-admin', 'closure'), 0.0013447610510889353)\n",
      "(('meet', 'wp'), 0.0013431781811784557)\n",
      "(('thanks', 'please'), 0.0013189828839754094)\n",
      "(('ca', \"n't\"), 0.0012638085613815469)\n",
      "(('wikipedia', 'articles'), 0.00094904357346902)\n",
      "(('gng', 'wp'), 0.0009180645480782037)\n",
      "(('coverage', 'reliable'), 0.0009130898140738391)\n",
      "((\"n't\", 'find'), 0.0007950529436066415)\n",
      "((\"n't\", 'see'), 0.0007292507801852727)\n",
      "(('article', \"'s\"), 0.0007265372889101646)\n",
      "(('meets', 'wp'), 0.0007154571995368071)\n",
      "(('wp', 'gng.'), 0.0007152310752638814)\n",
      "(('per', 'nom'), 0.0006951060149734971)\n",
      "(('find', 'sources'), 0.0006598306283970932)\n",
      "(('establish', 'notability'), 0.00063495695837527)\n",
      "(('books', 'scholar'), 0.0005956113348862041)\n",
      "(('newspapers', 'books'), 0.0005924455950652447)\n",
      "(('scholar', 'highbeam'), 0.0005886014824255084)\n",
      "(('highbeam', 'jstor'), 0.0005881492338796571)\n",
      "(('independent', 'reliable'), 0.0005770691445062994)\n",
      "((\"n't\", 'think'), 0.000540210888019416)\n",
      "(('notability', 'guidelines'), 0.0005399847637464903)\n",
      "(('independent', 'sources'), 0.0005379496452901593)\n",
      "(('reliable', 'source'), 0.000536140651106754)\n",
      "(('comment', 'added'), 0.0005264173073709504)\n",
      "(('unsigned', 'comment'), 0.0005223470704582883)\n",
      "(('secondary', 'sources'), 0.0005203119520019574)\n",
      "(('preceding', 'unsigned'), 0.0005200858277290317)\n",
      "(('evidence', 'notability'), 0.0005013175130762014)\n",
      "(('notable', 'enough'), 0.0004906896722486951)\n",
      "(('talk', 'page'), 0.0004588061497661762)\n",
      "(('pass', 'wp'), 0.0004513440487596292)\n",
      "(('passes', 'wp'), 0.00044569094193648757)\n",
      "(('looks', 'like'), 0.0004450125691177106)\n",
      "(('jstor', 'free'), 0.0004287316214670626)\n",
      "(('free', 'images'), 0.00042850549719413697)\n",
      "(('images', 'wikipedia'), 0.00042850549719413697)\n",
      "(('news', 'newspapers'), 0.00042782712437536)\n",
      "(('wikipedia', 'library'), 0.0004262442544648803)\n",
      "((\"n't\", 'seem'), 0.00042398301173562366)\n"
     ]
    }
   ],
   "source": [
    "for Bscore in Bscored[:50]:\n",
    "    print (Bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bfinder2 = BigramCollocationFinder.from_words(stopwikiDiswords)\n",
    "Bfinder2.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('burr', 'steers'), 19.75445270527577)\n",
      "(('helsingin', 'sanomat'), 19.75445270527577)\n",
      "(('hemorrhagic', 'conjunctivitis'), 19.75445270527577)\n",
      "(('inã©s', 'rodena'), 19.75445270527577)\n",
      "(('khyber', 'pakhtunkhwa'), 19.75445270527577)\n",
      "(('manadel', 'al-jamadi'), 19.75445270527577)\n",
      "(('mys', '721tx'), 19.75445270527577)\n",
      "(('pell', 'mell'), 19.75445270527577)\n",
      "(('phnom', 'penh'), 19.75445270527577)\n",
      "(('putroe', 'neng'), 19.75445270527577)\n",
      "(('rot-weiãÿ', 'oberhausen'), 19.75445270527577)\n",
      "(('schwã¤bisch', 'gmã¼nd'), 19.75445270527577)\n",
      "(('sunanda', 'pushkar'), 19.75445270527577)\n",
      "(('super-god', 'masterforce'), 19.75445270527577)\n",
      "(('vis-ã', '-vis'), 19.75445270527577)\n",
      "(('ashleigh', 'lollie'), 19.491418299441975)\n",
      "(('beent', 'agged'), 19.491418299441975)\n",
      "(('deletion/anshei', 'sfard'), 19.491418299441975)\n",
      "(('deletion/beth', 'hamedrosh'), 19.491418299441975)\n",
      "(('dudel250', 'chatprod'), 19.491418299441975)\n",
      "(('energy-safety', 'energy-economy'), 19.491418299441975)\n",
      "(('giro', \"d'italia\"), 19.491418299441975)\n",
      "(('hamedrosh', 'hagodol-beth'), 19.491418299441975)\n",
      "(('lorem', 'ipsum'), 19.491418299441975)\n",
      "(('m.j.', 'ramanan'), 19.491418299441975)\n",
      "(('margarita', 'martirena'), 19.491418299441975)\n",
      "(('mong', 'kok'), 19.491418299441975)\n",
      "(('movers', 'shakers'), 19.491418299441975)\n",
      "(('rls=org.mozilla', 'en-us'), 19.491418299441975)\n",
      "(('suhas', 'gopinath'), 19.491418299441975)\n",
      "(('ulrike', 'ottinger'), 19.491418299441975)\n",
      "(('vitalik', 'buterin'), 19.491418299441975)\n",
      "(('xhulio', 'joka'), 19.491418299441975)\n",
      "(('abdulhadi', 'najjar'), 19.269025878105527)\n",
      "(('aqueduct', 'racetrack'), 19.269025878105527)\n",
      "(('chal', 'jhoothey'), 19.269025878105527)\n",
      "(('charles_manson', 'tate_murders'), 19.269025878105527)\n",
      "(('deletion/tessa', 'campanelli'), 19.269025878105527)\n",
      "(('diante', 'trono'), 19.269025878105527)\n",
      "(('guo', 'dongli'), 19.269025878105527)\n",
      "(('hidy', 'ochiai'), 19.269025878105527)\n",
      "(('marlene', 'dietrich'), 19.269025878105527)\n",
      "(('mushtaq', 'pahalgami'), 19.269025878105527)\n",
      "(('officeâ€\\x9dwp', 'politition'), 19.269025878105527)\n",
      "(('option=com_content', 'view=article'), 19.269025878105527)\n",
      "(('politition', 'states-'), 19.269025878105527)\n",
      "(('rowman', 'littlefield'), 19.269025878105527)\n",
      "(('sadman', 'sakibzz'), 19.269025878105527)\n",
      "(('satish', 'rajwade'), 19.269025878105527)\n",
      "(('sebalu', 'lule'), 19.269025878105527)\n"
     ]
    }
   ],
   "source": [
    "Bscored = Bfinder2.score_ngrams(Bmeasures.pmi)\n",
    "for Bscore in Bscored[:50]:\n",
    "    print (Bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npschat = nltk.Text(nps_chat.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npswords = [w.lower() for w in Npschat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alphanpswords = [w for w in Npswords if not alphafilter(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npsdist = FreqDist(Alphanpswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npsitems = Npsdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0.027193956898467007\n",
      "part 0.02270606531881804\n",
      "join 0.022683848033770274\n",
      "lol 0.018262608309264607\n",
      "you 0.015241057542768274\n",
      "to 0.014774494556765163\n",
      "the 0.014663408131526327\n",
      "hi 0.014574538991335258\n",
      "a 0.012886025327704954\n",
      "me 0.009508998000444345\n",
      "is 0.008442568318151522\n",
      "in 0.008087091757387248\n",
      "and 0.007931570762052876\n",
      "it 0.007887136191957344\n",
      "action 0.007709397911575206\n",
      "hey 0.0064874472339480115\n",
      "that 0.0063097089535658745\n",
      "my 0.0057542768273716955\n",
      "of 0.004598978004887803\n",
      "u 0.004532326149744501\n",
      "what 0.0044656742946011995\n",
      "'s 0.004332370584314597\n",
      "on 0.004199066874027994\n",
      "for 0.004199066874027994\n",
      "here 0.004110197733836925\n",
      "are 0.004021328593645857\n",
      "do 0.004021328593645857\n",
      "no 0.004021328593645857\n",
      "not 0.003976894023550322\n",
      "have 0.003799155743168185\n",
      "all 0.0037325038880248835\n",
      "up 0.0035769828926905133\n",
      "like 0.003554765607642746\n",
      "with 0.003421461897356143\n",
      "im 0.0033103754721173074\n",
      "pm 0.0033103754721173074\n",
      "chat 0.0032437236169740057\n",
      "n't 0.0031992890468784713\n",
      "so 0.0031770717618307045\n",
      "your 0.0031548544767829373\n",
      "was 0.0031548544767829373\n",
      "how 0.0030659853365918683\n",
      "'m 0.0029548989113530326\n",
      "good 0.0029326816263052654\n",
      "any 0.002866029771161964\n",
      "lmao 0.002843812486114197\n",
      "just 0.002843812486114197\n",
      "too 0.0028215952010664297\n",
      "there 0.0026882914907798267\n",
      "u7 0.0026438569206842922\n"
     ]
    }
   ],
   "source": [
    "for item in Npsitems:\n",
    "    print(item[0], item[1]/len(Npswords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bfinder3 = BigramCollocationFinder.from_words(Alphanpswords)\n",
    "Scored3 = Bfinder3.score_ngrams(Bmeasures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('part', 'join'), 0.005006064046654452)\n",
      "(('join', 'part'), 0.003509405723427864)\n",
      "(('i', \"'m\"), 0.003431992361881661)\n",
      "(('part', 'part'), 0.0030449255541506464)\n",
      "(('join', 'join'), 0.0027868810156633033)\n",
      "(('pm', 'me'), 0.002374009754083555)\n",
      "(('in', 'the'), 0.0019869429463525404)\n",
      "(('i', 'am'), 0.0019095295848063376)\n",
      "(('are', 'you'), 0.0017288984078651975)\n",
      "(('wanna', 'chat'), 0.0015482672309240575)\n",
      "(('it', \"'s\"), 0.0014966583232265888)\n",
      "(('i', 'have'), 0.001419244961680386)\n",
      "(('join', 'hi'), 0.0013418316001341832)\n",
      "(('do', \"n't\"), 0.0013160271462854488)\n",
      "(('lol', 'i'), 0.0013160271462854488)\n",
      "(('join', 'i'), 0.0012902226924367147)\n",
      "(('i', 'was'), 0.001238613784739246)\n",
      "(('lol', 'lol'), 0.0012128093308905116)\n",
      "(('part', 'i'), 0.0012128093308905116)\n",
      "(('to', 'chat'), 0.0011870048770417775)\n",
      "(('lol', 'part'), 0.0011095915154955744)\n",
      "(('lol', 'hi'), 0.0010837870616468403)\n",
      "(('lol', 'join'), 0.0010837870616468403)\n",
      "(('want', 'to'), 0.0010837870616468403)\n",
      "(('on', 'the'), 0.0010321781539493716)\n",
      "(('part', 'hi'), 0.0010321781539493716)\n",
      "(('how', 'are'), 0.0010063737001006373)\n",
      "(('i', 'know'), 0.0010063737001006373)\n",
      "(('part', 'lol'), 0.0010063737001006373)\n",
      "(('join', 'action'), 0.000877351430856966)\n",
      "(('join', 'lol'), 0.000877351430856966)\n",
      "(('action', 'is'), 0.0008515469770082316)\n",
      "(('i', 'do'), 0.0008257425231594974)\n",
      "(('i', 'dont'), 0.0008257425231594974)\n",
      "(('in', 'here'), 0.0008257425231594974)\n",
      "(('have', 'a'), 0.000799938069310763)\n",
      "(('you', \"'re\"), 0.0007741336154620288)\n",
      "(('do', 'you'), 0.0007483291616132944)\n",
      "(('i', 'think'), 0.0007483291616132944)\n",
      "(('is', 'a'), 0.0007483291616132944)\n",
      "(('#14-19teens', 'o'), 0.0007225247077645602)\n",
      "(('i', 'just'), 0.0007225247077645602)\n",
      "(('mode', '#14-19teens'), 0.0007225247077645602)\n",
      "(('with', 'a'), 0.0007225247077645602)\n",
      "(('i', 'like'), 0.0006967202539158258)\n",
      "(('talk', 'to'), 0.0006967202539158258)\n",
      "(('to', 'me'), 0.0006967202539158258)\n",
      "(('i', 'can'), 0.0006709158000670916)\n",
      "(('me', 'if'), 0.0006709158000670916)\n",
      "(('part', 'action'), 0.0006709158000670916)\n"
     ]
    }
   ],
   "source": [
    "for bscore in Scored3[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bfinder4 = BigramCollocationFinder.from_words(Alphanpswords)\n",
    "Bfinder4.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('lez', 'gurls'), 12.242020378132263)\n",
      "(('gently', 'kisses'), 12.072095376689951)\n",
      "(('neck', 'compliments'), 11.809060970856155)\n",
      "(('fingers', 'thru'), 11.51955435366117)\n",
      "(('ice', 'cream'), 11.51955435366117)\n",
      "(('played', 'times'), 11.278546254157373)\n",
      "(('lime', 'player'), 11.154557536881923)\n",
      "(('lasts', 'minutes'), 11.072095376689951)\n",
      "(('cute.-ass', 'mp3'), 11.072095376689948)\n",
      "(('hair', 'closes'), 10.89152313104813)\n",
      "(('closes', 'their'), 10.731058458854882)\n",
      "(('minutes', 'seconds'), 10.657057877411106)\n",
      "(('talkin', 'bout'), 10.51955435366117)\n",
      "(('la', 'la'), 10.331127851966247)\n",
      "(('mp3', 'player'), 10.30656063032697)\n",
      "(('runs', 'their'), 10.146095958133726)\n",
      "(('their', 'fingers'), 9.856589340938744)\n",
      "(('song', 'lasts'), 9.849702955353502)\n",
      "(('mode', '#40splus'), 9.8497029553535)\n",
      "(('minutes', 'ago'), 9.750167281802586)\n",
      "(('mode', '#14-19teens'), 9.750167281802586)\n",
      "(('busy', 'busy'), 9.652057196352738)\n",
      "(('#14-19teens', 'o'), 9.387597202417878)\n",
      "(('their', 'eyes'), 9.31602095957604)\n",
      "(('#40splus', 'o'), 9.224098470135)\n",
      "(('u99', 'u99'), 9.13051206291527)\n",
      "(('been', 'played'), 9.121004977170893)\n",
      "(('f', 'c'), 8.946087491777844)\n",
      "(('f', 'tx'), 8.9200922832449)\n",
      "(('or', 'lez'), 8.71845842207525)\n",
      "(('u122', 'u122'), 8.627310534017054)\n",
      "(('at', 'least'), 8.598164188357536)\n",
      "(('mode', '#talkcity_adults'), 8.569595036160766)\n",
      "(('main', 'room'), 8.555519850949043)\n",
      "(('an', 'hour'), 8.51138042221547)\n",
      "(('talking', 'about'), 8.48713287596879)\n",
      "(('m', 'canada'), 8.330328796259924)\n",
      "(('last', 'night'), 8.279702723189951)\n",
      "(('times', 'this'), 8.248798910763322)\n",
      "(('#talkcity_adults', 'o'), 8.207024956776056)\n",
      "(('females', 'want'), 8.09227325862758)\n",
      "(('player', 'song'), 8.084168208990526)\n",
      "(('wo', \"n't\"), 8.07209537668995)\n",
      "(('last', 'seen'), 8.02146930361998)\n",
      "(('bi', 'or'), 7.981492827909042)\n",
      "(('long', 'time'), 7.956618159270009)\n",
      "(('song', 'has'), 7.916817151212038)\n",
      "(('player', 'this'), 7.861775787654075)\n",
      "(('who', 'sang'), 7.836028018456426)\n",
      "(('ca', \"n't\"), 7.831087277186153)\n"
     ]
    }
   ],
   "source": [
    "Scored4 = Bfinder4.score_ngrams(Bmeasures.pmi)\n",
    "for bscore in Scored4[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_letters = nltk.FreqDist('egbdafkjlmorcnst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "obligatory = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdomen',\n",
       " 'abelmosk',\n",
       " 'acneform',\n",
       " 'almond',\n",
       " 'almoner',\n",
       " 'almost',\n",
       " 'ambler',\n",
       " 'ambrose',\n",
       " 'amelcorn',\n",
       " 'amends',\n",
       " 'amlong',\n",
       " 'amober',\n",
       " 'amongst',\n",
       " 'amoret',\n",
       " 'angeldom',\n",
       " 'angstrom',\n",
       " 'antdom',\n",
       " 'armbone',\n",
       " 'armlet',\n",
       " 'asmoke',\n",
       " 'asmolder',\n",
       " 'atomerg',\n",
       " 'backmost',\n",
       " 'bakerdom',\n",
       " 'bankerdom',\n",
       " 'barksome',\n",
       " 'barmote',\n",
       " 'barsom',\n",
       " 'beardom',\n",
       " 'beastdom',\n",
       " 'becalm',\n",
       " 'beclamor',\n",
       " 'becram',\n",
       " 'bedamn',\n",
       " 'bedlam',\n",
       " 'bedman',\n",
       " 'befoam',\n",
       " 'beldam',\n",
       " 'beloam',\n",
       " 'beltman',\n",
       " 'bemask',\n",
       " 'bemoan',\n",
       " 'bemoat',\n",
       " 'bemock',\n",
       " 'bemolt',\n",
       " 'benmost',\n",
       " 'bergamot',\n",
       " 'bestorm',\n",
       " 'blamed',\n",
       " 'blamer',\n",
       " 'blastoderm',\n",
       " 'blockman',\n",
       " 'bogman',\n",
       " 'boltmaker',\n",
       " 'bregma',\n",
       " 'bromal',\n",
       " 'bromate',\n",
       " 'calmer',\n",
       " 'camber',\n",
       " 'cambrel',\n",
       " 'camlet',\n",
       " 'camstone',\n",
       " 'carmot',\n",
       " 'catdom',\n",
       " 'cembalo',\n",
       " 'ceroma',\n",
       " 'clamber',\n",
       " 'clamer',\n",
       " 'clamor',\n",
       " 'clerkdom',\n",
       " 'cloamen',\n",
       " 'cloamer',\n",
       " 'clogmaker',\n",
       " 'clomben',\n",
       " 'coagment',\n",
       " 'cobleman',\n",
       " 'codman',\n",
       " 'cogman',\n",
       " 'cokeman',\n",
       " 'colmar',\n",
       " 'comaker',\n",
       " 'comart',\n",
       " 'comate',\n",
       " 'combat',\n",
       " 'combater',\n",
       " 'combed',\n",
       " 'comber',\n",
       " 'comble',\n",
       " 'comrade',\n",
       " 'conamed',\n",
       " 'cormel',\n",
       " 'cotman',\n",
       " 'crambe',\n",
       " 'cramble',\n",
       " 'crambo',\n",
       " 'daemon',\n",
       " 'dambose',\n",
       " 'damner',\n",
       " 'damsel',\n",
       " 'damson',\n",
       " 'darksome',\n",
       " 'deform',\n",
       " 'demark',\n",
       " 'demast',\n",
       " 'democrat',\n",
       " 'dermal',\n",
       " 'dermoblast',\n",
       " 'dermol',\n",
       " 'desman',\n",
       " 'desmon',\n",
       " 'dockman',\n",
       " 'dockmaster',\n",
       " 'dogman',\n",
       " 'dolesman',\n",
       " 'dolman',\n",
       " 'dolmen',\n",
       " 'doment',\n",
       " 'dormant',\n",
       " 'dreamt',\n",
       " 'earldom',\n",
       " 'embank',\n",
       " 'embargo',\n",
       " 'embark',\n",
       " 'enamor',\n",
       " 'endmost',\n",
       " 'engram',\n",
       " 'enjamb',\n",
       " 'enmask',\n",
       " 'entomb',\n",
       " 'escambron',\n",
       " 'estmark',\n",
       " 'fabledom',\n",
       " 'fadmonger',\n",
       " 'famble',\n",
       " 'fandom',\n",
       " 'farmost',\n",
       " 'femora',\n",
       " 'femoral',\n",
       " 'flamberg',\n",
       " 'flamed',\n",
       " 'flamen',\n",
       " 'flamenco',\n",
       " 'flamer',\n",
       " 'flatdom',\n",
       " 'flockman',\n",
       " 'flockmaster',\n",
       " 'flogmaster',\n",
       " 'flotsam',\n",
       " 'foamer',\n",
       " 'foeman',\n",
       " 'fogman',\n",
       " 'fogram',\n",
       " 'foment',\n",
       " 'foramen',\n",
       " 'foreman',\n",
       " 'foremast',\n",
       " 'forgeman',\n",
       " 'forkman',\n",
       " 'formable',\n",
       " 'formagen',\n",
       " 'formal',\n",
       " 'formant',\n",
       " 'format',\n",
       " 'formate',\n",
       " 'formed',\n",
       " 'formel',\n",
       " 'fotmal',\n",
       " 'fragment',\n",
       " 'framed',\n",
       " 'freakdom',\n",
       " 'frogman',\n",
       " 'gambeson',\n",
       " 'gambet',\n",
       " 'gamble',\n",
       " 'gambler',\n",
       " 'gambol',\n",
       " 'gambrel',\n",
       " 'gamont',\n",
       " 'garment',\n",
       " 'gemsbok',\n",
       " 'geomant',\n",
       " 'germal',\n",
       " 'german',\n",
       " 'germon',\n",
       " 'gladsome',\n",
       " 'gnomed',\n",
       " 'godmaker',\n",
       " 'gomart',\n",
       " 'gomeral',\n",
       " 'gormed',\n",
       " 'graftdom',\n",
       " 'jambone',\n",
       " 'jambstone',\n",
       " 'jarldom',\n",
       " 'jasmone',\n",
       " 'jermonal',\n",
       " 'jetsam',\n",
       " 'jobman',\n",
       " 'jobmaster',\n",
       " 'katmon',\n",
       " 'kerslam',\n",
       " 'lambent',\n",
       " 'lamber',\n",
       " 'lambert',\n",
       " 'lament',\n",
       " 'landstorm',\n",
       " 'larksome',\n",
       " 'leafdom',\n",
       " 'legman',\n",
       " 'lemnad',\n",
       " 'lockerman',\n",
       " 'lockman',\n",
       " 'lockram',\n",
       " 'locksman',\n",
       " 'lodesman',\n",
       " 'lodgeman',\n",
       " 'lodgment',\n",
       " 'loftman',\n",
       " 'loftsman',\n",
       " 'logman',\n",
       " 'lombard',\n",
       " 'loment',\n",
       " 'mackle',\n",
       " 'macled',\n",
       " 'macron',\n",
       " 'madstone',\n",
       " 'maestro',\n",
       " 'magnes',\n",
       " 'magnet',\n",
       " 'magneto',\n",
       " 'magnetod',\n",
       " 'malfed',\n",
       " 'malter',\n",
       " 'maltose',\n",
       " 'manbot',\n",
       " 'mandore',\n",
       " 'mandrel',\n",
       " 'mangel',\n",
       " 'manger',\n",
       " 'mangle',\n",
       " 'mangler',\n",
       " 'manlet',\n",
       " 'manred',\n",
       " 'mantel',\n",
       " 'manter',\n",
       " 'mantes',\n",
       " 'mantle',\n",
       " 'mantled',\n",
       " 'marble',\n",
       " 'marbled',\n",
       " 'marbles',\n",
       " 'marcel',\n",
       " 'marengo',\n",
       " 'margent',\n",
       " 'marked',\n",
       " 'market',\n",
       " 'marled',\n",
       " 'marlock',\n",
       " 'martel',\n",
       " 'marten',\n",
       " 'mascled',\n",
       " 'mascot',\n",
       " 'masked',\n",
       " 'masker',\n",
       " 'masoned',\n",
       " 'masoner',\n",
       " 'masted',\n",
       " 'master',\n",
       " 'matfelon',\n",
       " 'matron',\n",
       " 'medlar',\n",
       " 'megadont',\n",
       " 'megaron',\n",
       " 'megaton',\n",
       " 'megotalc',\n",
       " 'melano',\n",
       " 'melosa',\n",
       " 'melton',\n",
       " 'menald',\n",
       " 'menfolk',\n",
       " 'mensal',\n",
       " 'mental',\n",
       " 'mentor',\n",
       " 'mercal',\n",
       " 'merfold',\n",
       " 'merfolk',\n",
       " 'merlon',\n",
       " 'mescal',\n",
       " 'mesobar',\n",
       " 'mobster',\n",
       " 'mockable',\n",
       " 'mocker',\n",
       " 'modena',\n",
       " 'moderant',\n",
       " 'modern',\n",
       " 'modest',\n",
       " 'molder',\n",
       " 'molecast',\n",
       " 'molest',\n",
       " 'molten',\n",
       " 'molter',\n",
       " 'monase',\n",
       " 'monaster',\n",
       " 'moneral',\n",
       " 'monger',\n",
       " 'mongler',\n",
       " 'mongrel',\n",
       " 'mongst',\n",
       " 'monkcraft',\n",
       " 'monster',\n",
       " 'montage',\n",
       " 'morale',\n",
       " 'morals',\n",
       " 'morate',\n",
       " 'mordant',\n",
       " 'mordent',\n",
       " 'morgan',\n",
       " 'morgen',\n",
       " 'morned',\n",
       " 'morsal',\n",
       " 'morsel',\n",
       " 'mortal',\n",
       " 'mosker',\n",
       " 'nearmost',\n",
       " 'neckmold',\n",
       " 'nemoral',\n",
       " 'normal',\n",
       " 'normated',\n",
       " 'omental',\n",
       " 'oreman',\n",
       " 'orgasm',\n",
       " 'osmate',\n",
       " 'ostmark',\n",
       " 'radome',\n",
       " 'ramble',\n",
       " 'rambong',\n",
       " 'rament',\n",
       " 'ramose',\n",
       " 'ramson',\n",
       " 'randem',\n",
       " 'random',\n",
       " 'ransom',\n",
       " 'recomb',\n",
       " 'remand',\n",
       " 'remask',\n",
       " 'remast',\n",
       " 'remock',\n",
       " 'remold',\n",
       " 'retomb',\n",
       " 'rockman',\n",
       " 'rodman',\n",
       " 'rodsman',\n",
       " 'romance',\n",
       " 'salmon',\n",
       " 'salmonet',\n",
       " 'samlet',\n",
       " 'sarment',\n",
       " 'scamble',\n",
       " 'scambler',\n",
       " 'scamler',\n",
       " 'scleroma',\n",
       " 'scramble',\n",
       " 'scream',\n",
       " 'seamrog',\n",
       " 'seldom',\n",
       " 'selfdom',\n",
       " 'semblant',\n",
       " 'semola',\n",
       " 'serfdom',\n",
       " 'sermon',\n",
       " 'sjambok',\n",
       " 'smacker',\n",
       " 'smalter',\n",
       " 'smarten',\n",
       " 'smocker',\n",
       " 'smoked',\n",
       " 'smoker',\n",
       " 'smolder',\n",
       " 'socman',\n",
       " 'sokeman',\n",
       " 'solemn',\n",
       " 'somber',\n",
       " 'sombre',\n",
       " 'sorema',\n",
       " 'stagedom',\n",
       " 'stamen',\n",
       " 'stardom',\n",
       " 'stockman',\n",
       " 'storeman',\n",
       " 'stormable',\n",
       " 'stream',\n",
       " 'stroam',\n",
       " 'stroma',\n",
       " 'stromal',\n",
       " 'stromb',\n",
       " 'strome',\n",
       " 'tamber',\n",
       " 'tambor',\n",
       " 'tandem',\n",
       " 'tarsome',\n",
       " 'telamon',\n",
       " 'temblor',\n",
       " 'termon',\n",
       " 'tombac',\n",
       " 'tombal',\n",
       " 'tormen',\n",
       " 'transmold',\n",
       " 'transom',\n",
       " 'transomed',\n",
       " 'tromba',\n",
       " 'trombe',\n",
       " 'tsardom',\n",
       " 'almost',\n",
       " 'market',\n",
       " 'normal']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if len(w) >= 6\n",
    " and obligatory in w\n",
    " and nltk.FreqDist(w) <= puzzle_letters]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
